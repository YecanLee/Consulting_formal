_BASE_: ../maskformer2_R50_bs16_50ep.yaml

MODEL:
  META_ARCHITECTURE: "MaskCLIPpp"
  WEIGHTS: ""
  MASKCLIPPP:
    VISUAL_ENCODER:
      NAME: "EVACLIPViT"
      MODEL_NAME: "EVA02-CLIP-L-14-336"
      PRETRAINED: "eva02_clip"
      OUT_FEATURES: ["m_embs"]
      FEATURE_SUFFIX: ""
      FINETUNE_TYPE: "attention"
      PIXEL_MEAN: [122.7709383, 116.7460125, 104.09373615]
      PIXEL_STD: [68.5005327, 66.6321579, 70.32316305]
      SIZE_DIVISIBILITY: 14
      RESIZE_TYPE: "none"
      TEST_RESIZE_TYPE: "short"
      TEST_IMAGE_SIZE: 392
      MASK_PRIOR_BEG: 22
      DOWNSAMPLE_METHOD: 'bilinear'
      DOWN_MASK_THRESH: None
      MASK_LOGIT_SCALE: -5.0
      LEARNABLE_MASK_LOGIT_SCALE: True
    TEXT_ENCODER:
      NAME: "EVACLIPTextEncoder"
      MODEL_NAME: "EVA02-CLIP-L-14-336"
      PRETRAINED: "eva02_clip"
      FINETUNE_TYPE: "attention"
    TEMPLATES: "t1"
    USE_LOGIT_SCALE: True
    PSM:
      NAME: "LinearPSM"
      CORR_WIDTH: 768
    CRITERION:
      NAME: "ReweightCELoss"
      TEMPERATURE: 1.0
      BALANCE_CLS: True
      IGNORE_EMPTY: True

SOLVER:
  OPTIMIZER: "ADAMW"
  CLIP_GRADIENTS:
    ENABLED: True
    CLIP_TYPE: "full_model"
    CLIP_VALUE: 0.01
    NORM_TYPE: 2.0
  AMP:
    ENABLED: True
  LR_SCHEDULER_NAME: "WarmupCosineLR"
  MAX_ITER: 20000
  BASE_LR: 2e-4
  BASE_LR_END: 1e-5
  VISUAL_ENCODER_MULTIPLIER: 0.01
  TEXT_ENCODER_MULTIPLIER: 0.01
  IMS_PER_BATCH: 4
  WARMUP_ITERS: 0
  CHECKPOINT_PERIOD: 4000
TEST:
  EVAL_PERIOD: 4000

INPUT:
  MIN_SIZE_TRAIN: !!python/object/apply:eval ["[int(x * 0.1 * 448) for x in range(3, 20)]"]
  MIN_SIZE_TRAIN_SAMPLING: "choice"
  MAX_SIZE_TRAIN: 4096
  MIN_SIZE_TEST: 512
  MAX_SIZE_TEST: 2048
  FORMAT: "RGB"
  CROP:
    ENABLED: True
    TYPE: "absolute"
    SIZE: (448, 448)
    SINGLE_CATEGORY_MAX_AREA: 1.0
  COLOR_AUG_SSD: True
  SIZE_DIVISIBILITY: -1
  DATASET_MAPPER_NAME: "mask_former_semantic"

DATALOADER:
  FILTER_EMPTY_ANNOTATIONS: True
  NUM_WORKERS: 4

VERSION: 2